{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a9b5be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a0fb0bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating connection with MySQL datbase\n",
    "\n",
    "user = \"brenobertolucci\"\n",
    "password = \"Panda190322\"\n",
    "url_banco = \"brenobertolucci.mysql.pythonanywhere-services.com\"\n",
    "nome_db = \"brenobertolucci$dados_anbima\"\n",
    "conn_str = f\"mysql+pymysql://{user}:{password}@{url_banco}/{nome_db}\"\n",
    "engine = create_engine(conn_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b9df992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting day of extraction\n",
    "yesterday =  datetime.date.today() - datetime.timedelta(days=1)\n",
    "\n",
    "year_ext = str(yesterday.year)[2:]\n",
    "\n",
    "if len(str(yesterday.month)) == 1:\n",
    "    month_ext = \"0\"+str(yesterday.month)\n",
    "else:\n",
    "    month_ext = str(yesterday.month)\n",
    "\n",
    "    \n",
    "if len(str(yesterday.day)) == 1:\n",
    "    day_ext = \"0\"+str(yesterday.day)\n",
    "else:\n",
    "    day_ext = str(yesterday.day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9466cf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cupom(index):\n",
    "    \n",
    "    if \"+\" in index:\n",
    "        clean_cupom= index.split('+')[1].replace(\"%\",\"\").strip()\n",
    "    else:\n",
    "        clean_cupom = index.split('do')[0].replace(\"%\",\"\").strip()\n",
    "        \n",
    "    return clean_cupom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a00bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_index(index):\n",
    "    \n",
    "    if \"+\" in index:\n",
    "        clean_index = index.split('+')[0].strip()\n",
    "    else:\n",
    "        clean_index = \"%DI\"\n",
    "        \n",
    "    return clean_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd5cb600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name(name):\n",
    "    \n",
    "    pattern_dirty = r'[\\(][\\*]*[\\)]'\n",
    "    pattern_clean = r''\n",
    "    name_clean = re.sub(pattern_dirty,pattern_clean,name).strip().replace(\"S/A\",\"SA\").replace(\"S.A.\",\"SA\").replace(\"S.A\",\"SA\")\n",
    "    \n",
    "    return name_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f0c98e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(string_to_clean):\n",
    "    \n",
    "    \n",
    "    pattern_dirty = r'[,]'\n",
    "    pattern_clean = r'.'\n",
    "    string_clean = re.sub(pattern_dirty,pattern_clean,string_to_clean)\n",
    "    \n",
    "    return string_clean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e21cd3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sql(query, engine):\n",
    "    with engine.begin() as conn:\n",
    "        results = pd.read_sql_query(sa.text(query), conn)\n",
    "    return results\n",
    "    \n",
    "def execute_sql(query, engine):\n",
    "    with engine.begin() as conn:\n",
    "        results = conn.execute(\n",
    "            sa.text(query)\n",
    "            )\n",
    "    return results\n",
    "\n",
    "def df_to_sql(df, table, engine):\n",
    "    with engine.begin() as conn:\n",
    "        df.to_sql(table ,conn, index = False, index_label = False, if_exists = \"append\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ab0d9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting info of debentures\n",
    "\n",
    "url_debs  = f\"https://www.anbima.com.br/informacoes/merc-sec-debentures/arqs/db{year_ext}{month_ext}{day_ext}.txt\"\n",
    "df_debs = pd.read_csv(url_debs,sep=\"@\",encoding=\"latin1\",skiprows=1)\n",
    "\n",
    "#cleaning index\n",
    "\n",
    "df_debs['Indexador'] = df_debs['Índice/ Correção'].map(clean_index)\n",
    "\n",
    "\n",
    "#cleaning cupom\n",
    "\n",
    "df_debs['Cupom'] = df_debs['Índice/ Correção'].map(clean_cupom).map(clean_string).astype(float)\n",
    "\n",
    "\n",
    "#converting the columns \"to date\n",
    "\n",
    "df_debs['Referência NTN-B'] = pd.to_datetime(df_debs['Referência NTN-B'])\n",
    "df_debs['Referência NTN-B'] = df_debs['Referência NTN-B'].dt.strftime('%Y-%m-%d')\n",
    "df_debs['Repac./  Venc.'] = pd.to_datetime(df_debs['Repac./  Venc.'])\n",
    "\n",
    "#cleaing name\n",
    "\n",
    "df_debs['Nome'] = df_debs['Nome'].map(clean_name)\n",
    "\n",
    "#converting  columns to float\n",
    "\n",
    "df_debs['PU'] = df_debs['PU'].replace(\"N/D\",str(\"1000000\")).map(clean_string).replace(\"1000000\",np.nan).astype(float) \n",
    "df_debs['Duration'] = df_debs['Duration'].replace(\"N/D\",str(\"1000000\")).map(clean_string).replace(\"1000000\",np.nan).astype(float) \n",
    "df_debs['% PU Par'] = df_debs['% PU Par'].replace(\"N/D\",str(\"1000000\")).map(clean_string).replace(\"1000000\",np.nan).astype(float) \n",
    "df_debs['Taxa de Compra'] = df_debs['Taxa de Compra'].replace(\"--\",str(\"1000000\")).map(clean_string).replace(\"1000000\",np.nan).astype(float) \n",
    "df_debs['Taxa Indicativa'] = df_debs['Taxa Indicativa'].replace(\"--\",str(\"1000000\")).map(clean_string).replace(\"1000000\",np.nan).astype(float) \n",
    "df_debs['Taxa de Venda'] = df_debs['Taxa de Venda'].replace(\"--\",str(\"1000000\")).map(clean_string).replace(\"1000000\",np.nan).astype(float) \n",
    "\n",
    "\n",
    "#creating column date\n",
    "\n",
    "df_debs['Data'] = yesterday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "708f4bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting info of public titles\n",
    "url_pt  = f\"https://www.anbima.com.br/informacoes/merc-sec/arqs/ms{year_ext}{month_ext}{day_ext}.txt\"\n",
    "df_pt = pd.read_csv(url_pt,sep=\"@\",encoding=\"latin1\",skiprows=1)\n",
    "\n",
    "#converting the columns \"Data Vencimento\" to date\n",
    "\n",
    "df_pt['Data Vencimento'] = df_pt['Data Vencimento'].astype(str)\n",
    "df_pt['Data Vencimento'] = pd.to_datetime(df_pt['Data Vencimento'])\n",
    "df_pt['Data Vencimento'] = df_pt['Data Vencimento'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "#converting rates columns to float\n",
    "\n",
    "df_pt['Tx. Compra'] = df_pt['Tx. Compra'].map(clean_string).astype(float) \n",
    "df_pt['Tx. Indicativas'] = df_pt['Tx. Indicativas'].map(clean_string).astype(float) \n",
    "df_pt['Tx. Venda'] = df_pt['Tx. Venda'].map(clean_string).astype(float) \n",
    "\n",
    "\n",
    "#selecting only relevants columns\n",
    "df_pt = df_pt[['Titulo','Data Vencimento','Tx. Compra','Tx. Indicativas','Tx. Venda']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8ae982d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the NTN-B rate to the Debs DF\n",
    "df_full = pd.merge(df_debs, df_pt, left_on=\"Referência NTN-B\", right_on = \"Data Vencimento\", how=\"left\")\n",
    "\n",
    "#creating key\n",
    "df_full['ID'] = df_full[\"Código\"] + str(yesterday)\n",
    "\n",
    "#cleaning nans\n",
    "df_full['Tx. Compra'] = df_full['Tx. Compra'].replace(np.nan,0)\n",
    "df_full['Tx. Indicativas'] = df_full['Tx. Indicativas'].replace(np.nan,0)\n",
    "df_full['Tx. Venda'] = df_full['Tx. Venda'].replace(np.nan,0)\n",
    "\n",
    "#calculating spreads\n",
    "\n",
    "df_full[\"Spread_Compra\"] = ((1+df_full['Taxa de Compra']/100)/(1+df_full[\"Tx. Compra\"]/100)-1)*100\n",
    "df_full[\"Spread_Indicativo\"] = ((1+df_full['Taxa Indicativa']/100)/(1+df_full[\"Tx. Indicativas\"]/100)-1)*100\n",
    "df_full[\"Spread_Venda\"] = ((1+df_full['Taxa de Venda']/100)/(1+df_full[\"Tx. Venda\"]/100)-1)*100\n",
    "\n",
    "\n",
    "#selecting only relevants columns and chanhing names\n",
    "\n",
    "\n",
    "df_full=df_full[['ID','Data','Código',\"Nome\",\"Repac./  Venc.\",\"Indexador\",'Cupom',\"Taxa de Compra\",\n",
    "          \"Taxa Indicativa\",\"Taxa de Venda\",'PU','% PU Par','Duration',\n",
    "          'Referência NTN-B','Spread_Compra','Spread_Indicativo','Spread_Venda']]\n",
    "\n",
    "df_full.columns = ['ID','Data','Ticker','Emissor',\"Vencimento\",\"Indexador\",'Cupom',\"Taxa_Compra\",\n",
    "          \"Taxa_Indicativa\",\"Taxa_Venda\",'PU','Perc_Par','Duration',\n",
    "          'Ref_B','Spread_Compra','Spread_Indicativo','Spread_Venda']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e2e32e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting daily files:\n",
    "\n",
    "#sql\n",
    "\n",
    "df_to_sql(df_full,\"dados_anbima\",engine)\n",
    "\n",
    "#excel\n",
    "\n",
    "name_file_xlsx = str(year_ext)+str(month_ext)+str(day_ext)+\"_ANBIMA.xlsx\"\n",
    "df_full.to_excel(f'daily_files/{name_file_xlsx}')\n",
    "\n",
    "#json\n",
    "name_file_json = str(year_ext)+str(month_ext)+str(day_ext)+\"_ANBIMA.json\"\n",
    "df_full.to_json(f'daily_files/{name_file_json}', orient = 'index')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ca4aa21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating table with sectos \n",
    "\n",
    "#importing historic table\n",
    "\n",
    "df_historico = read_sql('select * from dados_anbima',engine)\n",
    "\n",
    "#importing setores\n",
    "\n",
    "setores = read_sql('select * from setores_anbima',engine)\n",
    "\n",
    "#merging tables\n",
    "\n",
    "df_historico_setores = pd.merge(df_historico, setores,how=\"left\")\n",
    "\n",
    "#exporting files\n",
    "df_historico_setores.to_excel('daily_files/historico_setores.xlsx')\n",
    "df_historico_setores.to_json('daily_files/historico_setores.json', orient = 'index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64337bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
